{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load e-mails data to dataframe\n",
    "2. Data analysis & preparation for classification\n",
    "3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"D:\\Download\\Trainingsmails_Anonym\"\n",
    "del_ = str.maketrans(\"\",\"\", string.punctuation) # for deleting punctuation\n",
    "del_galki=str.maketrans(\"\",\"\", \"<>\") # for deleting <> in email addresses\n",
    "NEWLINE=\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_base(tree):# makes dataframe from e-mail From, Subject & body w/o punctuation. only for .eml format, ignores errors in coding\n",
    "    base=pd.DataFrame(columns=[\"Text\", \"Label\"])\n",
    "    for address, _, file in tree:\n",
    "        for ff in file: \n",
    "            if not ff.endswith(\".eml\"):\n",
    "                continue\n",
    "            path = os.path.join(address,ff)\n",
    "            with open(path, \"r\", errors='ignore', encoding=\"utf-8\") as f:\n",
    "                pased_header, lines=False, []\n",
    "                for line in f:\n",
    "                    if line.startswith(\"From:\"):\n",
    "                        line=line.replace(\"From: \", \"\").lower().translate(del_galki).replace(\"\\n\", \"\")\n",
    "                        lines.append(line)\n",
    "                    if line.startswith(\"Subject:\"):\n",
    "                        line=line.replace(\"Subject: \", \"\").lower().translate(del_).replace(\"\\n\", \"\").translate(del_galki) \n",
    "                        lines.append(line)\n",
    "                    if pased_header:\n",
    "                        line=line.lower().translate(del_).replace(\"\\n\", \"\").translate(del_galki)\n",
    "                        lines.append(line)\n",
    "                    elif line==NEWLINE:\n",
    "                        pased_header=True\n",
    "            content=NEWLINE.join(lines)            \n",
    "            label=address.split(\"\\\\\")[-1]\n",
    "            row=pd.DataFrame({\"Text\":[content], \"Label\": [label]})\n",
    "            base=base.append(row, ignore_index=True)\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_base(tree): # makes dataframe with features w/o <> and punctuation. only for .eml format, ignores errors in coding\n",
    "    base=pd.DataFrame(columns=[\"Text\", \"Label\"])\n",
    "    for address, _, file in tree: \n",
    "        for ff in file: \n",
    "            if not ff.endswith(\".eml\"):\n",
    "                continue\n",
    "            path = os.path.join(address,ff)\n",
    "            with open(path, \"r\", errors='ignore', encoding=\"utf8\") as f:\n",
    "                text=[]\n",
    "                for line in f:\n",
    "                    if line.startswith(\"From:\"):\n",
    "                        line=line.replace(\"From: \", \"\").lower().translate(del_galki).replace(\"\\n\", \"\") \n",
    "                        lines=line +\" \"\n",
    "                    if line.startswith(\"Subject:\"):\n",
    "                        line=line.replace(\"Subject: \", \"\").lower().translate(del_).replace(\"\\n\", \"\").translate(del_galki)  \n",
    "                        lines=lines + line\n",
    "                        text.append(lines)            \n",
    "            label=address.split(\"\\\\\")[-1]\n",
    "            row=pd.DataFrame({\"Text\":text, \"Label\": label})\n",
    "            base=base.append(row, ignore_index=True)\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon.de promotion5@amazon.de\\nhund hündin ho...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon.de promotion5@amazon.de\\nmilestone baby...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon.de promotion5@amazon.de\\namazonde empfi...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon.de promotion5@amazon.de\\namazonde empfi...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon.de promotion5@amazon.de\\namazonde empfi...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text             Label\n",
       "0  amazon.de promotion5@amazon.de\\nhund hündin ho...  Amazon - diverse\n",
       "1  amazon.de promotion5@amazon.de\\nmilestone baby...  Amazon - diverse\n",
       "2  amazon.de promotion5@amazon.de\\namazonde empfi...  Amazon - diverse\n",
       "3  amazon.de promotion5@amazon.de\\namazonde empfi...  Amazon - diverse\n",
       "4  amazon.de promotion5@amazon.de\\namazonde empfi...  Amazon - diverse"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=os.walk(directory)\n",
    "base=to_base(tree)\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- other common approaches to deal with text? Process punctuation, numbers, special symbols like <>, etc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Issues | Do now | Plan |\n",
    "| --- | --- | --- |\n",
    "| Imbalanced classes | as it is | try over-sampling methods |\n",
    "| Nested folders | flatten to 16 classes | need advise |\n",
    "| Features scope | use  only From & Subject info | add email body  |\n",
    "| Features engineering | in bulk | separate features for From/Subject? how to do it?  |\n",
    "| Stemming/lemmatizing | no  | apply smth. what? |\n",
    "| Labels |  strings  | code as numbers? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis & preparation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=base[\"Label\"]\n",
    "X=base[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding labels\n",
    "feature_codes=zip( [i for i in range(0,16)], y.unique())\n",
    "feature_codes={j: i for i,j in feature_codes} #dictionary folder: number\n",
    "y=list(map(lambda i: feature_codes[i],y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 16 artists>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd237518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#highly imbalanced data set,gonna use oversampling later\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.bar(Counter(y).keys(), Counter(y).values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix warnings as f1 score is ill-defines for small classes \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>cv_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>650</td>\n",
       "      <td>10</td>\n",
       "      <td>0.964108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>0.960808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550</td>\n",
       "      <td>5</td>\n",
       "      <td>0.959480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "      <td>10</td>\n",
       "      <td>0.956716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550</td>\n",
       "      <td>10</td>\n",
       "      <td>0.955184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>5</td>\n",
       "      <td>0.955077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>650</td>\n",
       "      <td>5</td>\n",
       "      <td>0.953316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>0.951877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max min  cv_f1_score\n",
       "0  650  10     0.964108\n",
       "1  700  10     0.960808\n",
       "2  550   5     0.959480\n",
       "3  600  10     0.956716\n",
       "4  550  10     0.955184\n",
       "5  600   5     0.955077\n",
       "6  650   5     0.953316\n",
       "7  700   5     0.951877"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking for optimal words frequency to form a dictionary( define rare and buzz-words). I used all the base. Is it correct?\n",
    "\n",
    "f1_scorer=metrics.make_scorer(metrics.f1_score, average=\"weighted\" )\n",
    "result=pd.DataFrame(columns=[\"max\", \"min\", \"cv_f1_score\"])\n",
    "max_df= [ 550, 600, 650, 700]\n",
    "min_df= [ 5, 10]\n",
    "for i in max_df:\n",
    "    for j in min_df:\n",
    "        vectorizer = CountVectorizer(max_df=i, min_df=j)\n",
    "        vectorizer.fit(X)\n",
    "        clf= LogisticRegression()\n",
    "        clf.fit(vectorizer.transform(X), y)\n",
    "        cvs=cross_val_score(clf, vectorizer.transform(X), y, \n",
    "                            cv=list(StratifiedShuffleSplit(test_size=0.3).split(X,y)), \n",
    "                            scoring=f1_scorer,\n",
    "                           n_jobs=-1)\n",
    "        row=pd.DataFrame([[i, j, cvs.mean()]],columns=[\"max\", \"min\", \"cv_f1_score\"] )\n",
    "        result=result.append(row, ignore_index=True)\n",
    "result=result.sort_values(\"cv_f1_score\", ascending=False).reset_index(drop=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>cv_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.958407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.957961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram  cv_f1_score\n",
       "0  (1, 2)     0.958407\n",
       "1  (1, 3)     0.957961"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I continue with 10<words frequency <650 and check if n_gram improves result. Seems like not really\n",
    "result1=pd.DataFrame(columns=[ \"ngram\", \"cv_f1_score\"])\n",
    "ngram= [ (1,2), (1,3)]\n",
    "for i in ngram:\n",
    "    vectorizer = CountVectorizer(max_df=650, min_df=10, ngram_range=i)\n",
    "    vectorizer.fit(X)\n",
    "    clf= LogisticRegression()\n",
    "    clf.fit(vectorizer.transform(X), y)\n",
    "    cvs=cross_val_score(clf, vectorizer.transform(X), y, \n",
    "                            cv=list(StratifiedShuffleSplit(test_size=0.3).split(X,y)), \n",
    "                            scoring=f1_scorer,\n",
    "                           n_jobs=-1)\n",
    "    row=pd.DataFrame([[i, cvs.mean()]],columns=[ \"ngram\", \"cv_f1_score\"] )\n",
    "    result1=result1.append(row, ignore_index=True)\n",
    "result1=result1.sort_values(\"cv_f1_score\", ascending=False).reset_index(drop=True)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform text features to a matrix of tokened counts with 10<words frequency <650\n",
    "vectorizer=CountVectorizer(max_df=650, min_df=10)\n",
    "vectorizer.fit(X)\n",
    "X_vect=vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample process \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros=RandomOverSampler()\n",
    "X_res, y_res = ros.fit_sample(X_vect,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 305), (1, 305), (2, 305), (3, 305), (4, 305), (5, 305), (6, 305), (7, 305), (8, 305), (9, 305), (10, 305), (11, 305), (12, 305), (13, 305), (14, 305), (15, 305)])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_res).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepate train & test samples for resampled data\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_res, y_res, \n",
    "                                                  test_size=0.2, \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  train & test samples for initial data w/o resampling\n",
    "X_train_, X_test_, y_train_, y_test_=train_test_split(X_vect, y, \n",
    "                                                  test_size=0.2, \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- other ways to create dictionary?\n",
    "- common approach to text oversampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer=metrics.make_scorer(metrics.f1_score, average=\"weighted\")\n",
    "clf=LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "cvs=cross_val_score(clf, X_train, y_train, cv=5, scoring=scorer, n_jobs=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914826198222793"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high result on cross validation\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       0.97      1.00      0.98        62\n",
      "          2       1.00      1.00      1.00        41\n",
      "          3       1.00      1.00      1.00        22\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00        29\n",
      "          7       1.00      1.00      1.00        12\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      0.96      0.98        45\n",
      "         11       1.00      1.00      1.00        13\n",
      "         12       1.00      1.00      1.00         4\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00        26\n",
      "         15       1.00      1.00      1.00         7\n",
      "\n",
      "avg / total       0.99      0.99      0.99       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the same result on test sample\n",
    "print(metrics.classification_report(clf.predict(X_test_), y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to improve model with grid search \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.5, 1, 2], 'solver': ['lbfgs', 'newton-cg', 'liblinear', 'sag']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=make_scorer(f1_score, average=weighted), verbose=0)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={\"C\": [0.5, 1, 2],\n",
    "        \"solver\": [\"lbfgs\", \"newton-cg\", \"liblinear\", \"sag\"]\n",
    "    \n",
    "}\n",
    "grid=GridSearchCV(LogisticRegression(), param_grid=params, cv=5, scoring=scorer, n_jobs=-1, return_train_score=False)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2, 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       0.98      1.00      0.99        63\n",
      "          2       0.98      0.98      0.98        41\n",
      "          3       1.00      1.00      1.00        22\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       0.97      1.00      0.98        28\n",
      "          7       1.00      1.00      1.00        12\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      0.98      0.99        44\n",
      "         11       1.00      1.00      1.00        13\n",
      "         12       1.00      1.00      1.00         4\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00        26\n",
      "         15       1.00      0.88      0.93         8\n",
      "\n",
      "avg / total       0.99      0.99      0.99       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(grid.best_estimator_.predict(X_test_), y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([17.7158,  9.4579,  9.5083, 22.0255, 21.7058, 10.5524,  8.4683,\n",
       "        23.2319,  4.355 , 12.7491, 10.3836, 22.0559]),\n",
       " 'mean_score_time': array([0.0052, 0.0056, 0.0054, 0.0058, 0.0054, 0.0058, 0.0054, 0.007 ,\n",
       "        0.0058, 0.0092, 0.0056, 0.0052]),\n",
       " 'mean_test_score': array([0.9907, 0.9907, 0.9905, 0.9766, 0.991 , 0.991 , 0.9907, 0.9763,\n",
       "        0.991 , 0.991 , 0.991 , 0.9763]),\n",
       " 'param_C': masked_array(data=[0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 2, 2, 2, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['lbfgs', 'newton-cg', 'liblinear', 'sag', 'lbfgs',\n",
       "                    'newton-cg', 'liblinear', 'sag', 'lbfgs', 'newton-cg',\n",
       "                    'liblinear', 'sag'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.5000, 'solver': 'lbfgs'},\n",
       "  {'C': 0.5000, 'solver': 'newton-cg'},\n",
       "  {'C': 0.5000, 'solver': 'liblinear'},\n",
       "  {'C': 0.5000, 'solver': 'sag'},\n",
       "  {'C': 1, 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'solver': 'newton-cg'},\n",
       "  {'C': 1, 'solver': 'liblinear'},\n",
       "  {'C': 1, 'solver': 'sag'},\n",
       "  {'C': 2, 'solver': 'lbfgs'},\n",
       "  {'C': 2, 'solver': 'newton-cg'},\n",
       "  {'C': 2, 'solver': 'liblinear'},\n",
       "  {'C': 2, 'solver': 'sag'}],\n",
       " 'rank_test_score': array([ 7,  7,  9, 10,  2,  2,  6, 11,  2,  2,  1, 11]),\n",
       " 'split0_test_score': array([0.9935, 0.9935, 0.9923, 0.9793, 0.9935, 0.9935, 0.9935, 0.9793,\n",
       "        0.9935, 0.9935, 0.9935, 0.9793]),\n",
       " 'split1_test_score': array([0.9949, 0.9949, 0.9962, 0.9846, 0.9949, 0.9949, 0.9962, 0.9846,\n",
       "        0.9949, 0.9949, 0.9962, 0.9846]),\n",
       " 'split2_test_score': array([0.9885, 0.9885, 0.9897, 0.9729, 0.9885, 0.9885, 0.9897, 0.9715,\n",
       "        0.9885, 0.9885, 0.9897, 0.9715]),\n",
       " 'split3_test_score': array([0.9923, 0.9923, 0.991 , 0.9792, 0.9936, 0.9936, 0.991 , 0.9792,\n",
       "        0.9936, 0.9936, 0.9923, 0.9792]),\n",
       " 'split4_test_score': array([0.9842, 0.9842, 0.983 , 0.9668, 0.9842, 0.9842, 0.983 , 0.9668,\n",
       "        0.9842, 0.9842, 0.983 , 0.9668]),\n",
       " 'std_fit_time': array([17.0681,  0.1704,  5.6053,  0.8146, 24.3763,  1.664 ,  1.7998,\n",
       "         1.823 ,  0.0309,  1.0441,  4.3524,  3.8495]),\n",
       " 'std_score_time': array([0.0004, 0.0005, 0.0005, 0.0007, 0.0008, 0.0012, 0.0005, 0.0009,\n",
       "        0.0012, 0.003 , 0.0008, 0.001 ]),\n",
       " 'std_test_score': array([0.0038, 0.0038, 0.0043, 0.0061, 0.004 , 0.004 , 0.0044, 0.0063,\n",
       "        0.004 , 0.004 , 0.0045, 0.0063])}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like not a big improvement, thus stay with the last variant - Logistic Regression solver lfbgs, c=1.\n",
    "#Test sample f1score 0.99, cross_val score 0.991\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- other algorithms? I tried MultinomialNB, result is worse\n",
    "- how to tune LogisticRegression? Check if results improvement are statistically significant?\n",
    "- rationale for using other scoring functions?\n",
    "- how to increase precision in classification_report?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
