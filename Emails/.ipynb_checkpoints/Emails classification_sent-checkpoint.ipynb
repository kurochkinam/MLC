{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load e-mails data to dataframe\n",
    "2. Data analysis & preparation for classification\n",
    "3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"D:\\Download\\Trainingsmails_Anonym\"\n",
    "del_ = str.maketrans(\"\",\"\", string.punctuation) # for deleting punctuation\n",
    "del_galki=str.maketrans(\"\",\"\", \"<>\") # for deleting <> in email addresses\n",
    "NEWLINE=\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_base(tree):# makes dataframe from e-mail From, Subject & body w/o punctuation. only for .eml format, ignores errors in coding\n",
    "    base=pd.DataFrame(columns=[\"Text\", \"Label\"])\n",
    "    for address, _, file in tree:\n",
    "        for ff in file: \n",
    "            if not ff.endswith(\".eml\"):\n",
    "                continue\n",
    "            path = os.path.join(address,ff)\n",
    "            with open(path, \"r\", errors='ignore', encoding=\"utf-8\") as f:\n",
    "                pased_header, lines=False, []\n",
    "                for line in f:\n",
    "                    if line.startswith(\"From:\"):\n",
    "                        line=line.replace(\"From: \", \"\").lower().translate(del_galki).replace(\"\\n\", \"\")\n",
    "                        lines.append(line)\n",
    "                    if line.startswith(\"Subject:\"):\n",
    "                        line=line.replace(\"Subject: \", \"\").lower().translate(del_).replace(\"\\n\", \"\").translate(del_galki) \n",
    "                        lines.append(line)\n",
    "                    if pased_header:\n",
    "                        line=line.lower().translate(del_).replace(\"\\n\", \"\").translate(del_galki)\n",
    "                        lines.append(line)\n",
    "                    elif line==NEWLINE:\n",
    "                        pased_header=True\n",
    "            content=NEWLINE.join(lines)            \n",
    "            label=address.split(\"\\\\\")[-1]\n",
    "            row=pd.DataFrame({\"Text\":[content], \"Label\": [label]})\n",
    "            base=base.append(row, ignore_index=True)\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_base(tree): # makes dataframe with features w/o <> and punctuation. only for .eml format, ignores errors in coding\n",
    "    base=pd.DataFrame(columns=[\"Text\", \"Label\"])\n",
    "    for address, _, file in tree: \n",
    "        for ff in file: \n",
    "            if not ff.endswith(\".eml\"):\n",
    "                continue\n",
    "            path = os.path.join(address,ff)\n",
    "            with open(path, \"r\", errors='ignore', encoding=\"utf8\") as f:\n",
    "                text=[]\n",
    "                for line in f:\n",
    "                    if line.startswith(\"From:\"):\n",
    "                        line=line.replace(\"From: \", \"\").lower().translate(del_galki).replace(\"\\n\", \"\") \n",
    "                        lines=line +\" \"\n",
    "                    if line.startswith(\"Subject:\"):\n",
    "                        line=line.replace(\"Subject: \", \"\").lower().translate(del_).replace(\"\\n\", \"\").translate(del_galki)  \n",
    "                        lines=lines + line\n",
    "                        text.append(lines)            \n",
    "            label=address.split(\"\\\\\")[-1]\n",
    "            row=pd.DataFrame({\"Text\":text, \"Label\": label})\n",
    "            base=base.append(row, ignore_index=True)\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon.de promotion5@amazon.de hund hündin hos...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon.de promotion5@amazon.de milestone baby ...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon.de promotion5@amazon.de amazonde empfie...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon.de promotion5@amazon.de amazonde empfie...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon.de promotion5@amazon.de amazonde empfie...</td>\n",
       "      <td>Amazon - diverse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text             Label\n",
       "0  amazon.de promotion5@amazon.de hund hündin hos...  Amazon - diverse\n",
       "1  amazon.de promotion5@amazon.de milestone baby ...  Amazon - diverse\n",
       "2  amazon.de promotion5@amazon.de amazonde empfie...  Amazon - diverse\n",
       "3  amazon.de promotion5@amazon.de amazonde empfie...  Amazon - diverse\n",
       "4  amazon.de promotion5@amazon.de amazonde empfie...  Amazon - diverse"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=os.walk(directory)\n",
    "base=to_base(tree)\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- other common approaches to deal with text? Process punctuation, numbers, special symbols like <>, etc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis & preparation for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=base[\"Label\"]\n",
    "X=base[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding labels\n",
    "feature_codes=zip( [i for i in range(0,16)], y.unique())\n",
    "feature_codes={j: i for i,j in feature_codes} #dictionary folder: number\n",
    "y=list(map(lambda i: feature_codes[i],y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 16 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb543240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#highly imbalanced data set,gonna use oversampling later\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.bar(Counter(y).keys(), Counter(y).values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix warnings as f1 score is ill-defines for small classes \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for optimal words frequency to form a dictionary( define rare and buzz-words). I used all the base. Is it correct?\n",
    "\n",
    "f1_scorer=metrics.make_scorer(metrics.f1_score, average=\"weighted\" )\n",
    "result=pd.DataFrame(columns=[\"max\", \"min\", \"cv_f1_score\"])\n",
    "max_df= [  600, 650, 700, 800]\n",
    "min_df= [ 5, 10]\n",
    "for i in max_df:\n",
    "    for j in min_df:\n",
    "        vectorizer = CountVectorizer(max_df=i, min_df=j)\n",
    "        vectorizer.fit(X)\n",
    "        clf= LogisticRegression()\n",
    "        clf.fit(vectorizer.transform(X), y)\n",
    "        cvs=cross_val_score(clf, vectorizer.transform(X), y, \n",
    "                            cv=list(StratifiedShuffleSplit(test_size=0.3).split(X,y)), \n",
    "                            scoring=f1_scorer,\n",
    "                           n_jobs=-1)\n",
    "        row=pd.DataFrame([[i, j, cvs.mean()]],columns=[\"max\", \"min\", \"cv_f1_score\"] )\n",
    "        result=result.append(row, ignore_index=True)\n",
    "result=result.sort_values(\"cv_f1_score\", ascending=False).reset_index(drop=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>cv_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.958407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.957961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ngram  cv_f1_score\n",
       "0  (1, 2)     0.958407\n",
       "1  (1, 3)     0.957961"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I continue with 10<words frequency <650 and check if n_gram improves result. Seems like not really\n",
    "result1=pd.DataFrame(columns=[ \"ngram\", \"cv_f1_score\"])\n",
    "ngram= [ (1,2), (1,3)]\n",
    "for i in ngram:\n",
    "    vectorizer = CountVectorizer(max_df=650, min_df=10, ngram_range=i)\n",
    "    vectorizer.fit(X)\n",
    "    clf= LogisticRegression()\n",
    "    clf.fit(vectorizer.transform(X), y)\n",
    "    cvs=cross_val_score(clf, vectorizer.transform(X), y, \n",
    "                            cv=list(StratifiedShuffleSplit(test_size=0.3).split(X,y)), \n",
    "                            scoring=f1_scorer,\n",
    "                           n_jobs=-1)\n",
    "    row=pd.DataFrame([[i, cvs.mean()]],columns=[ \"ngram\", \"cv_f1_score\"] )\n",
    "    result1=result1.append(row, ignore_index=True)\n",
    "result1=result1.sort_values(\"cv_f1_score\", ascending=False).reset_index(drop=True)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform text features to a matrix of tokened counts with 10<words frequency <650\n",
    "vectorizer=CountVectorizer(max_df=650, min_df=10)\n",
    "vectorizer.fit(X)\n",
    "X_vect=vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample process \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros=RandomOverSampler()\n",
    "X_res, y_res = ros.fit_sample(X_vect,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 305), (1, 305), (2, 305), (3, 305), (4, 305), (5, 305), (6, 305), (7, 305), (8, 305), (9, 305), (10, 305), (11, 305), (12, 305), (13, 305), (14, 305), (15, 305)])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_res).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepate train & test samples for resampled data\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_res, y_res, \n",
    "                                                  test_size=0.2, \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  train & test samples for initial data w/o resampling\n",
    "X_train_, X_test_, y_train_, y_test_=train_test_split(X_vect, y, \n",
    "                                                  test_size=0.2, \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- other ways to create dictionary?\n",
    "- common approach to text oversampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer=metrics.make_scorer(metrics.f1_score, average=\"weighted\")\n",
    "clf=LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "cvs=cross_val_score(clf, X_train, y_train, cv=5, scoring=scorer, n_jobs=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914826198222793"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high result on cross validation\n",
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       0.97      1.00      0.98        62\n",
      "          2       1.00      1.00      1.00        41\n",
      "          3       1.00      1.00      1.00        22\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00        29\n",
      "          7       1.00      1.00      1.00        12\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      0.96      0.98        45\n",
      "         11       1.00      1.00      1.00        13\n",
      "         12       1.00      1.00      1.00         4\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00        26\n",
      "         15       1.00      1.00      1.00         7\n",
      "\n",
      "avg / total       0.99      0.99      0.99       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the same result on test sample\n",
    "print(metrics.classification_report(clf.predict(X_test_), y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to improve model with grid search \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.5, 1, 2], 'solver': ['lbfgs', 'newton-cg', 'liblinear', 'sag']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=make_scorer(f1_score, average=weighted), verbose=0)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={\"C\": [0.5, 1, 2],\n",
    "        \"solver\": [\"lbfgs\", \"newton-cg\", \"liblinear\", \"sag\"]\n",
    "    \n",
    "}\n",
    "grid=GridSearchCV(LogisticRegression(), param_grid=params, cv=5, scoring=scorer, n_jobs=-1, return_train_score=False)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2, 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       0.98      1.00      0.99        63\n",
      "          2       0.98      0.98      0.98        41\n",
      "          3       1.00      1.00      1.00        22\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       0.97      1.00      0.98        28\n",
      "          7       1.00      1.00      1.00        12\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         2\n",
      "         10       1.00      0.98      0.99        44\n",
      "         11       1.00      1.00      1.00        13\n",
      "         12       1.00      1.00      1.00         4\n",
      "         13       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00        26\n",
      "         15       1.00      0.88      0.93         8\n",
      "\n",
      "avg / total       0.99      0.99      0.99       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(grid.best_estimator_.predict(X_test_), y_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([17.7158,  9.4579,  9.5083, 22.0255, 21.7058, 10.5524,  8.4683,\n",
       "        23.2319,  4.355 , 12.7491, 10.3836, 22.0559]),\n",
       " 'mean_score_time': array([0.0052, 0.0056, 0.0054, 0.0058, 0.0054, 0.0058, 0.0054, 0.007 ,\n",
       "        0.0058, 0.0092, 0.0056, 0.0052]),\n",
       " 'mean_test_score': array([0.9907, 0.9907, 0.9905, 0.9766, 0.991 , 0.991 , 0.9907, 0.9763,\n",
       "        0.991 , 0.991 , 0.991 , 0.9763]),\n",
       " 'param_C': masked_array(data=[0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 2, 2, 2, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['lbfgs', 'newton-cg', 'liblinear', 'sag', 'lbfgs',\n",
       "                    'newton-cg', 'liblinear', 'sag', 'lbfgs', 'newton-cg',\n",
       "                    'liblinear', 'sag'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.5000, 'solver': 'lbfgs'},\n",
       "  {'C': 0.5000, 'solver': 'newton-cg'},\n",
       "  {'C': 0.5000, 'solver': 'liblinear'},\n",
       "  {'C': 0.5000, 'solver': 'sag'},\n",
       "  {'C': 1, 'solver': 'lbfgs'},\n",
       "  {'C': 1, 'solver': 'newton-cg'},\n",
       "  {'C': 1, 'solver': 'liblinear'},\n",
       "  {'C': 1, 'solver': 'sag'},\n",
       "  {'C': 2, 'solver': 'lbfgs'},\n",
       "  {'C': 2, 'solver': 'newton-cg'},\n",
       "  {'C': 2, 'solver': 'liblinear'},\n",
       "  {'C': 2, 'solver': 'sag'}],\n",
       " 'rank_test_score': array([ 7,  7,  9, 10,  2,  2,  6, 11,  2,  2,  1, 11]),\n",
       " 'split0_test_score': array([0.9935, 0.9935, 0.9923, 0.9793, 0.9935, 0.9935, 0.9935, 0.9793,\n",
       "        0.9935, 0.9935, 0.9935, 0.9793]),\n",
       " 'split1_test_score': array([0.9949, 0.9949, 0.9962, 0.9846, 0.9949, 0.9949, 0.9962, 0.9846,\n",
       "        0.9949, 0.9949, 0.9962, 0.9846]),\n",
       " 'split2_test_score': array([0.9885, 0.9885, 0.9897, 0.9729, 0.9885, 0.9885, 0.9897, 0.9715,\n",
       "        0.9885, 0.9885, 0.9897, 0.9715]),\n",
       " 'split3_test_score': array([0.9923, 0.9923, 0.991 , 0.9792, 0.9936, 0.9936, 0.991 , 0.9792,\n",
       "        0.9936, 0.9936, 0.9923, 0.9792]),\n",
       " 'split4_test_score': array([0.9842, 0.9842, 0.983 , 0.9668, 0.9842, 0.9842, 0.983 , 0.9668,\n",
       "        0.9842, 0.9842, 0.983 , 0.9668]),\n",
       " 'std_fit_time': array([17.0681,  0.1704,  5.6053,  0.8146, 24.3763,  1.664 ,  1.7998,\n",
       "         1.823 ,  0.0309,  1.0441,  4.3524,  3.8495]),\n",
       " 'std_score_time': array([0.0004, 0.0005, 0.0005, 0.0007, 0.0008, 0.0012, 0.0005, 0.0009,\n",
       "        0.0012, 0.003 , 0.0008, 0.001 ]),\n",
       " 'std_test_score': array([0.0038, 0.0038, 0.0043, 0.0061, 0.004 , 0.004 , 0.0044, 0.0063,\n",
       "        0.004 , 0.004 , 0.0045, 0.0063])}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like not a big improvement, thus stay with the last variant - Logistic Regression solver lfbgs, c=1.\n",
    "#Test sample f1score 0.99, cross_val score 0.991\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- other algorithms? I tried MultinomialNB, result is worse\n",
    "- how to tune LogisticRegression? Check if results improvement are statistically significant?\n",
    "- rationale for using other scoring functions?\n",
    "- how to increase precision in classification_report?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
