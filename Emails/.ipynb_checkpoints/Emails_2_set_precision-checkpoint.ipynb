{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"D:\\Download\\Trainingsmails_Anonym\"\n",
    "del_ = str.maketrans(\"\",\"\", string.punctuation)\n",
    "del_galki=str.maketrans(\"\",\"\", \"<>\")\n",
    "NEWLINE=\"\\n\"\n",
    "# может цифры тоже поудалять?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_base(tree):\n",
    "    base=pd.DataFrame(columns=[\"Text\", \"Label\"])\n",
    "    for address, _, file in tree: #проход по всем папкам-\n",
    "        for ff in file: # проход по всем файлам в папке\n",
    "            if not ff.endswith(\".eml\"):\n",
    "                continue\n",
    "            path = os.path.join(address,ff)\n",
    "            with open(path, \"r\", errors='ignore', encoding=\"utf-8\") as f:\n",
    "                pased_header, lines=False, []\n",
    "                for line in f:\n",
    "                    if line.startswith(\"From:\"):\n",
    "                        line=line.replace(\"From: \", \"\").lower().translate(del_galki).replace(\"\\n\", \"\")\n",
    "                        lines.append(line)\n",
    "                    if line.startswith(\"Subject:\"):\n",
    "                        line=line.replace(\"Subject: \", \"\").lower().translate(del_).replace(\"\\n\", \"\").translate(del_galki)  #удалять переносы?\n",
    "                        lines.append(line)\n",
    "                    if pased_header:\n",
    "                        line=line.lower().translate(del_).replace(\"\\n\", \"\").translate(del_galki)\n",
    "                        lines.append(line)\n",
    "                    elif line==NEWLINE:\n",
    "                        pased_header=True\n",
    "            content=NEWLINE.join(lines)            \n",
    "            label=address.split(\"\\\\\")[-1]\n",
    "            row=pd.DataFrame({\"Text\":[content], \"Label\": [label]})\n",
    "            base=base.append(row, ignore_index=True)\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "base=to_base(os.walk(directory))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedShuffleSplit \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=base[\"Text\"]\n",
    "y=base[\"Label\"]\n",
    "\n",
    "feature_codes=zip( [i for i in range(0,16)], y.unique())\n",
    "feature_codes={j: i for i,j in feature_codes} #dictionary folder: number\n",
    "y=list(map(lambda i: feature_codes[i],y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amazon - diverse': 0, 'Angebote-Werbung-Newsletter': 1, 'BestellbestTДaetigungen': 2, 'Amazon': 3, 'Kino': 4, 'Mietwagen': 5, 'Rechnungen': 6, 'Reisen': 7, 'Retoure': 8, 'Veranstaltungen': 9, 'VersandbestaeTДtigung': 10, 'DHL': 11, 'DPD': 12, 'GLS': 13, 'UPS': 14, 'Zahlungseingang': 15}\n"
     ]
    }
   ],
   "source": [
    "print(feature_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(0, 41), (1, 305), (2, 189), (3, 138), (4, 9), (5, 5), (6, 128), (7, 73), (8, 6), (9, 20), (10, 203), (11, 69), (12, 15), (13, 25), (14, 135), (15, 28)])\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y).items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, \n",
    "                                                  test_size=0.2, \n",
    "                                                  stratify=y, \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>cv_accuracy</th>\n",
       "      <th>test_sample_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>0.946980</td>\n",
       "      <td>0.960432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>720</td>\n",
       "      <td>5</td>\n",
       "      <td>0.946120</td>\n",
       "      <td>0.964029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>720</td>\n",
       "      <td>10</td>\n",
       "      <td>0.945207</td>\n",
       "      <td>0.967626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>710</td>\n",
       "      <td>10</td>\n",
       "      <td>0.945193</td>\n",
       "      <td>0.960432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>0.944318</td>\n",
       "      <td>0.956835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>710</td>\n",
       "      <td>5</td>\n",
       "      <td>0.944318</td>\n",
       "      <td>0.960432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max min  cv_accuracy  test_sample_accuracy\n",
       "0  700  10     0.946980              0.960432\n",
       "1  720   5     0.946120              0.964029\n",
       "2  720  10     0.945207              0.967626\n",
       "3  710  10     0.945193              0.960432\n",
       "4  700   5     0.944318              0.956835\n",
       "5  710   5     0.944318              0.960432"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.DataFrame(columns=[\"max\", \"min\", \"cv_accuracy\", \"test_sample_accuracy\"])\n",
    "max_df= [ 700, 710, 720]\n",
    "min_df= [5, 10]\n",
    "for i in max_df:\n",
    "    for j in min_df:\n",
    "        vectorizer = CountVectorizer(max_df=i, min_df=j)\n",
    "        vectorizer.fit(X)\n",
    "        clf= LogisticRegression(solver=\"lbfgs\")\n",
    "        clf.fit(vectorizer.transform(X_train), y_train)\n",
    "        cvs=cross_val_score(clf, vectorizer.transform(X_train), y_train, cv=3, scoring=\"accuracy\")\n",
    "        acc=metrics.accuracy_score(clf.predict(vectorizer.transform(X_test)) , y_test)\n",
    "        row=pd.DataFrame([[i, j, cvs.mean(), acc ]],columns=[\"max\", \"min\", \"cv_accuracy\", \"test_sample_accuracy\"] )\n",
    "        result=result.append(row, ignore_index=True)\n",
    "result=result.sort_values(\"cv_accuracy\", ascending=False).reset_index(drop=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_df=700, min_df=10)\n",
    "vectorizer.fit(X)\n",
    "clf= LogisticRegression()\n",
    "clf.fit(vectorizer.transform(X_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.93         7\n",
      "          1       0.98      0.97      0.98        62\n",
      "          2       0.92      0.97      0.95        36\n",
      "          3       1.00      0.97      0.98        29\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      0.96      0.98        27\n",
      "          7       0.93      1.00      0.96        13\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         4\n",
      "         10       0.93      0.95      0.94        40\n",
      "         11       1.00      0.88      0.93        16\n",
      "         12       1.00      1.00      1.00         3\n",
      "         13       1.00      1.00      1.00         5\n",
      "         14       1.00      1.00      1.00        27\n",
      "         15       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       0.97      0.97      0.97       278\n",
      "\n",
      "0.9676258992805755\n"
     ]
    }
   ],
   "source": [
    "#np.set_printoptions(precision=3)\n",
    "print(metrics.classification_report(clf.predict(vectorizer.transform(X_test)), y_test))\n",
    "print(metrics.accuracy_score(clf.predict(vectorizer.transform(X_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Admin\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Admin\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Admin\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Admin\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Admin\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Admin\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scorer=metrics.make_scorer(metrics.f1_score, average=\"weighted\")\n",
    "cvs=cross_val_score(clf, vectorizer.transform(X_train), y_train, cv=StratifiedShuffleSplit(n_splits=10, test_size=0.3), scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953958567111618"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vect=vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros=RandomOverSampler()\n",
    "X_res, y_res=ros.fit_sample(X_vect,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 305), (1, 305), (2, 305), (3, 305), (4, 305), (5, 305), (6, 305), (7, 305), (8, 305), (9, 305), (10, 305), (11, 305), (12, 305), (13, 305), (14, 305), (15, 305)])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_res).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=LogisticRegression()\n",
    "cvs1=cross_val_score(clf1, X_train_res, y_train_res, cv=StratifiedShuffleSplit(n_splits=10, test_size=0.3), scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892097496482599"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       1.00      1.00      1.00        61\n",
      "          2       1.00      0.97      0.99        39\n",
      "          3       1.00      1.00      1.00        28\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00        26\n",
      "          7       1.00      1.00      1.00        14\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         4\n",
      "         10       0.90      1.00      0.95        37\n",
      "         11       1.00      0.88      0.93        16\n",
      "         12       1.00      0.75      0.86         4\n",
      "         13       1.00      1.00      1.00         5\n",
      "         14       1.00      1.00      1.00        27\n",
      "         15       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       0.99      0.99      0.99       278\n",
      "\n",
      "0.9856115107913669\n"
     ]
    }
   ],
   "source": [
    "X_train_res, _, y_train_res, _=train_test_split(X_res, y_res, \n",
    "                                                  test_size=0.3, \n",
    "                                                  shuffle=True)\n",
    "clf1.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(metrics.classification_report(clf1.predict(vectorizer.transform(X_test)), y_test))\n",
    "print(metrics.accuracy_score(clf1.predict(vectorizer.transform(X_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=0.3,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.2, 0.5, 1, 2], 'penalty': ['l1', 'l2'], 'fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(f1_score, average=weighted), verbose=0)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={\"C\": [0.2, 0.5, 1, 2],\n",
    "       \"penalty\": [\"l1\", \"l2\"],\n",
    "       \"fit_intercept\": [True, False]}\n",
    "grid=GridSearchCV(LogisticRegression(),\n",
    "                  param_grid=params, \n",
    "                  cv=StratifiedShuffleSplit(n_splits=10, test_size=0.3), \n",
    "                  scoring=scorer )\n",
    "grid.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'fit_intercept': True, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_multinom=LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "clf_multinom.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       1.00      1.00      1.00        61\n",
      "          2       1.00      0.97      0.99        39\n",
      "          3       1.00      1.00      1.00        28\n",
      "          4       1.00      1.00      1.00         2\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00        26\n",
      "          7       1.00      1.00      1.00        14\n",
      "          8       1.00      1.00      1.00         1\n",
      "          9       1.00      1.00      1.00         4\n",
      "         10       0.93      1.00      0.96        38\n",
      "         11       1.00      0.93      0.97        15\n",
      "         12       1.00      0.75      0.86         4\n",
      "         13       1.00      1.00      1.00         5\n",
      "         14       1.00      1.00      1.00        27\n",
      "         15       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       0.99      0.99      0.99       278\n",
      "\n",
      "0.9892086330935251\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(clf_multinom.predict(vectorizer.transform(X_test)), y_test))\n",
    "print(metrics.accuracy_score(clf_multinom.predict(vectorizer.transform(X_test)), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_multinom=cross_val_score(clf_multinom, X_train_res, y_train_res, \n",
    "                             cv=StratifiedShuffleSplit(n_splits=10, test_size=0.3), \n",
    "                             scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918556024583822"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs_multinom.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c35046a98168>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-28cf79d391c1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-28cf79d391c1>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    | Issues | Do now | Plan |\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "| Issues | Do now | Plan |\n",
    "| --- | --- | --- |\n",
    "| Imbalanced classes | as it is | try over-sampling methods |\n",
    "| Nested folders | flatten to 16 classes | need advise |\n",
    "| Features scope | use  only From & Subject info | add email body  |\n",
    "| Features engineering | in bulk | separate features for From/Subject? how to do it?  |\n",
    "| Stemming/lemmatizing | no  | apply smth. what? |\n",
    "| Labels |  strings  | code as numbers? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Issues | Do now | Plan |\n",
    "| --- | --- | --- |\n",
    "| Imbalanced classes | as it is | try over-sampling methods |\n",
    "| Nested folders | flatten to 16 classes | need advise |\n",
    "| Features scope | use  only From & Subject info | add email body  |\n",
    "| Features engineering | in bulk | separate features for From/Subject? how to do it?  |\n",
    "| Stemming/lemmatizing | no  | apply smth. what? |\n",
    "| Labels |  strings  | code as numbers? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
